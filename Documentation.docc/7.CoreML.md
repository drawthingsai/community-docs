# CoreML


## Using CoreML for faster image generation



Go to settings and there is processor bottom, click and you can read the description here carefully and check the bottom benchmark’s. For phones, it can be slow or crash the app. Most useful for iPads or MacBooks. 

Making sure your resolution is set to 512x512 only. Make sure you have enough disk space (5 GiB free disk space is a good number) and restart the app. CoreML support 1.X and 2.X models with limitation of 512x512 resolution. You can use CoreML for inpainting models, pix2pix and depth2img models as well. 

Here you can check some benchmark on MacBook Air M1 from or helpful users @Firewatch and below MacBook Pro M1 from @Artificial Content 

![benchmark](https://cdn.discordapp.com/attachments/1041451862987124866/1065611863041257472/Screenshot_20230119-133959_Fogli2.png?ex=66056562&is=65f2f062&hm=6f6cecc24f0784681bb3e2fe42aeaff533b0b95d0b66c3ed19f4cd3a7fe97e03&)

Why CoreML generate different images with same settings and seed then without CoreML?

Liuliu: There are some numerical differences between DT and CoreML, in particular, some non performance sensitive ones in DT we use fp32 for accuracy reasons (mostly around normalization) while CoreML is fp16 throughout. For CoreML itself, there are some numerical differences between ANE and GPU it seems.

If you use very long prompt or negative prompt (more then 77 words), CoreML can be turned off back to CPU, so generating images will get slow like without using CoreML, it’s limitation of CoreML now. 

DT only uses CoreML (if you enable it) in best case scenarios (512x512, no longer than 77 tokens, no ControlNet). Otherwise it uses GPU like PyTorch (A1111) and other peers. 


*Written by: F_R_O_S_T_Y*
